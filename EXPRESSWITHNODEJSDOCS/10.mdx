Теме #10 (Node.js): Стримы (Streams) и Буферы (Buffers):

1. Что такое Стримы (Потоки)?

Идея: В Node.js стримы — это абстрактные интерфейсы для работы с потоковыми данными. Вместо того чтобы загружать все данные (например, большой файл или сетевой ответ) в оперативную память целиком, стримы позволяют обрабатывать их порциями (чанками) по мере поступления.
Главное Преимущество: Эффективность по Памяти! Это ключевая причина использовать стримы. Представь обработку видеофайла размером в несколько гигабайт. fs.readFile попытается загрузить всё в ОЗУ, что почти наверняка приведет к краху процесса из-за нехватки памяти. Стримы позволяют читать небольшой чанк, обработать его (например, отправить по сети, сжать, проанализировать), прочитать следующий чанк и так далее, используя минимальный объем ОЗУ.
Аналогия: Думай о данных как о потоке воды, текущем по трубам.
2. Типы Стримов в Node.js:

Все стримы в Node.js построены на основе EventEmitter (Тема #6). Основные типы:

Readable Streams (Читаемые): Источники данных, из которых можно читать (fs.createReadStream для файлов, http.IncomingMessage - тело запроса, process.stdin - стандартный ввод). Генерируют события:
'data': При поступлении очередного чанка данных (обычно Buffer).
'end': Когда данные закончились.
'error': При ошибке чтения.
'close': При закрытии источника.
Writable Streams (Записываемые): Приемники данных, в которые можно писать (fs.createWriteStream для файлов, http.ServerResponse - тело ответа, process.stdout - стандартный вывод). Имеют методы:
.write(chunk, [encoding], [callback]): Записать чанк данных. Возвращает false, если внутренний буфер переполнен (сигнал для приостановки записи - backpressure).
.end([chunk], [encoding], [callback]): Завершить запись, опционально записав последний чанк.
Генерируют события: 'finish' (когда все данные записаны), 'error', 'drain' (когда можно возобновить запись после write вернул false).
Duplex Streams (Дуплексные): Одновременно читаемые и записываемые (например, net.Socket для TCP-соединений).
Transform Streams (Трансформирующие): Особый вид Duplex, который может модифицировать данные по мере их прохождения (например, zlib.createGzip() для сжатия, crypto.createCipheriv() для шифрования).
3. Метод .pipe() – Элегантное Соединение

Что делает: Это самый простой и распространенный способ соединить Readable Stream с Writable Stream. readable.pipe(writable) автоматически читает данные из readable и записывает их в writable.
Преимущества:
Простота: Одна строка вместо ручной обработки событий 'data', 'end', .write().
Обработка Backpressure: pipe() автоматически управляет скоростью потока. Если writable не успевает записывать (его .write() возвращает false), pipe() приостановит readable, дождется события 'drain' от writable и возобновит чтение. Это предотвращает переполнение памяти данными, которые еще не успели записаться.
Пример (Копирование файла):
JavaScript

const fs = require('fs');
const path = require('path');

const sourcePath = path.join(__dirname, 'source-file.txt'); // Исходный файл
const destPath = path.join(__dirname, 'destination-file.txt'); // Файл назначения

const reader = fs.createReadStream(sourcePath);
const writer = fs.createWriteStream(destPath);

console.log("Начинаем копирование через pipe...");

// Соединяем поток чтения с потоком записи
reader.pipe(writer);

// ОБЯЗАТЕЛЬНО: Обрабатываем ошибки на каждом стриме! pipe не передает ошибки.
reader.on('error', (err) => {
  console.error('Ошибка чтения:', err);
  // Важно также закрыть/уничтожить writer, если reader сломался
  writer.close();
});
writer.on('error', (err) => {
  console.error('Ошибка записи:', err);
});
writer.on('finish', () => { // 'finish' для Writable, 'end' для Readable
  console.log('Копирование успешно завершено!');
});
Критический взгляд: pipe() великолепен для простых соединений, но имеет недостаток: ошибки не передаются по цепочке автоматически. Если в середине цепочки a.pipe(b).pipe(c) стрим b выдаст ошибку, a и c об этом не узнают и могут остаться в некорректном состоянии.
4. stream.pipeline() – Надежное Соединение (Предпочтительно)

Что делает: Утилита из модуля stream (или stream/promises), специально созданная для надежного соединения нескольких стримов в конвейер.
Преимущества:
Автоматическая передача ошибок: Ошибка в любом стриме в цепочке автоматически уничтожает все остальные стримы и вызывает финальный колбэк с ошибкой.
Гарантированная очистка ресурсов.
Пример:
JavaScript

const { pipeline } = require('stream'); // Или require('stream/promises') для промисов
const fs = require('fs');
const zlib = require('zlib'); // Пример Transform stream для сжатия

// Конвейер: Чтение -> Сжатие -> Запись
pipeline(
  fs.createReadStream('archive.tar'),
  zlib.createGzip(),
  fs.createWriteStream('archive.tar.gz'),
  (err) => { // Колбэк выполнится по завершении или при ошибке
    if (err) {
      console.error('Ошибка конвейера:', err);
    } else {
      console.log('Конвейер успешно завершен.');
    }
  }
);
Критический взгляд: Для соединения нескольких стримов (source -> transform -> destination) всегда используйте pipeline, а не ручной чейнинг .pipe().pipe(), из-за надежной обработки ошибок.
5. Буферы (Buffer) – Работа с Бинарными Данными

Что это? Встроенный в Node.js класс для представления последовательностей байт (бинарных данных). JavaScript исторически плохо работал с бинарными данными, поэтому Node предоставил Buffer.
Зачем? Файлы (картинки, видео, архивы), сетевые пакеты, криптография — все это часто работает с сырыми байтами, а не только с текстом (строками).
Как связаны со Стримами: По умолчанию, Readable стримы (вроде fs.createReadStream без указания кодировки) выдают данные в событии 'data' именно как объекты Buffer. Writable стримы также могут принимать Buffer на вход.
Основные Операции:
Создание: Buffer.alloc(size) (безопасный, заполнен нулями), Buffer.from(string, [encoding]), Buffer.from(array).
Преобразование в строку: buf.toString([encoding]) (например, 'utf8', 'hex', 'base64'). Важно указывать правильную кодировку!
Длина в байтах: buf.length.
Доступ к байтам: buf[index].
Множество методов для чтения/записи чисел разной битности и порядка байт (readIntBE, writeUInt16LE и т.д.).
Критический взгляд: Понимание того, когда вы работаете со строкой (string), а когда с бинарными данными (Buffer), критически важно. Неправильное преобразование кодировок или попытка интерпретировать бинарные данные как UTF-8 строку (или наоборот) — частый источник багов и повреждения данных. Buffer доступен глобально в Node.js, что подчеркивает его фундаментальность.
Итог по Теме #10:

Стримы — это фундаментальный механизм Node.js для эффективной работы с I/O, позволяющий обрабатывать большие объемы данных с минимальным потреблением памяти. pipe() и особенно pipeline() предоставляют удобные и надежные способы их соединения. Buffer — это инструмент для работы с бинарными данными, которые часто передаются через стримы. Освоение стримов необходимо для написания производительных и масштабируемых Node.js приложений, работающих с файлами или сетью.
